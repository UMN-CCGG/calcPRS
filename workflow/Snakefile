# load modules
import glob
import os
import subprocess
import pdb
import shutil
import yaml
import pandas as pd
import numpy as np

# Get the date
from datetime import datetime
i = datetime.now()
TIME = i.strftime('%Y-%m-%d')

# specify config file
configfile: "workflow/config.yml"

# parse config.yml file
OUT = config['outname']
MODELNAME = config['model_name']
GENONAME = config['genotype_name']
MODELBUILD = config['model_build']
GENOBUILD = config['genotype_build']
MODELFILE = config['model_file']
GENODATA = config['genotype_data']
PYTHON = config['python']
CROSSMAP = config['CrossMap']['exec']

# are the liftover chains provided, or do we need to download -- downloading will take some debugging for now (12/7/2022)
CHAIN_TO_19 = config['CrossMap']['chain_to_hg19']
CHAIN_TO_38 = config['CrossMap']['chain_to_hg38']
if config['CrossMap']['download_chains'] == 'true':
        CHAIN_TO_19 = f"{os.getcwd()}/CrossMapRefData/{os.path.basename(CHAIN_TO_19)}"
        CHAIN_TO_38 = f"{os.getcwd()}/CrossMapRefData/{os.path.basename(CHAIN_TO_38)}"
else:
    assert (CHAIN_TO_19 != "none" and CHAIN_TO_38 != "none"), "Must provide both liftover chain files in workflow/config.yml file"
    assert os.path.exists(config['CrossMap']['chain_to_hg19']), f"Did not find liftover chain: {config['CrossMap']['chain_to_hg19']}"
    assert os.path.exists(config['CrossMap']['chain_to_hg38']), f"Did not find liftover chain: {config['CrossMap']['chain_to_hg38']}"

# make subdirectories
if not os.path.exists("CrossMapRefData"): os.mkdir("CrossMapRefData")
if not os.path.exists("accessory"): os.mkdir("accessory")
if not os.path.exists("OandE"): os.mkdir("OandE")

if not os.path.exists(MODELNAME):
	os.mkdir(MODELNAME)
	os.mkdir(f"{MODELNAME}/tmp")
	os.mkdir(f"{MODELNAME}/lifted")
if not os.path.exists(f"{MODELNAME}/{GENONAME}"):
	os.mkdir(f"{MODELNAME}/{GENONAME}")
	os.mkdir(f"{MODELNAME}/{GENONAME}/tmp")

# run locally or submit to cluster depending on config.yml
run_specs = {'__default__':""} # set default to empty string in case of local run
if config['run_settings']['local_run'] == 'true':
	localrules: all # add rule names here once written
else:
	localrules: all
	assert config['run_settings']['scheduler'] in ['pbs', 'slurm'], print(f"\nThe scheduler specified in run_settings -> scheduler: \'{config['run_settings']['scheduler']}\' is invalid.\n")
	assert os.path.exists(config['run_settings']['cluster_config']), print(f"\nMust provide a cluster configuration file under run_settings -> cluster_config in the config.yml file\nFile \'{config['run_settings']['cluster_config']}\' does not exist\n")
	clusterfile = yaml.load(open(config['run_settings']['cluster_config']), Loader=yaml.FullLoader)

# Conditionally set expected outputs of various steps depending on flags in config.yml
def get_all_inputs(wildcards):
#	input_list = [f"{OUT}-report.pdf"]
#	input_list += expand(f"{{model}}/{{geno}}_final_model", model=MODEL.keys(), geno=GENOTYPE.keys())
	input_list = expand(f"{MODELNAME}/lifted/{MODELNAME}_lifted.bed.unmap")
	input_list += expand(f"{MODELNAME}/tmp/duplicated.snp")
	input_list += expand(f"{MODELNAME}/tmp/{MODELNAME}.bed")
	input_list += expand(f"{MODELNAME}/CLEAN_REF_{MODELNAME}.txt")
	input_list += expand(f"{MODELNAME}/CLEAN_REF_{MODELNAME}.txt")
#	input_list += expand(f"{MODELNAME}/lifted/{MODELNAME}_lifted.bed.unmap")
	return(input_list)

def get_crossmap_inputs(wildcards):
    input_list = [CHAIN_TO_19, CHAIN_TO_38]
    input_list += [f"{MODELNAME}/tmp/{MODELNAME}.bed"]
    return(input_list)

def get_remove_unlifted_variants_input(wildcards):
	input_list = [f"{MODELNAME}/lifted/{MODELNAME}_lifted.bed.unmap"]
	return(input_list)


rule all: #Main function that determines which files snakemake will attempt to produce upon running
	input: get_all_inputs

rule check_model_for_duplicates: # check model for duplicated sites
	input: MODELFILE
	output: "{MODELNAME}/tmp/duplicated.snp"
	params:
		prefix = "{MODELNAME}/tmp/duplicated",
		awk_string = "\'FNR > 1 {print $1,$2,$3,$4}\' OFS=\':\'"
	run:
		shell(f"grep -v ^# {MODELFILE} | awk {{params.awk_string}} | sort | uniq -d > {{params.prefix}}.snp")

rule make_bed: # make bed file from published PGS model
	input: MODELFILE
	output: "{MODELNAME}/tmp/{MODELNAME}.bed"
	params:
		prefix = "{MODELNAME}/tmp/{MODELNAME}",
		awk_string = "\'FNR>1{print $1, $2-1, $2}\' OFS=\'\\t\'"
	run:
		shell(f"grep -v ^# {MODELFILE} | awk {{params.awk_string}} > {{params.prefix}}.bed")

rule cross_map: # Convert coordinates, if needed
	input: get_crossmap_inputs
	output: f"{MODELNAME}/lifted/{MODELNAME}_lifted.bed.unmap"
#	output: f"{MODELNAME}/lifted/{MODELNAME}_lifted.bed, {MODELNAME}/lifted/{MODELNAME}_lifted.bed.unmap"
	run:
		if MODELBUILD != GENOBUILD:
			if GENOBUILD == "hg38":
				shell(f"{CROSSMAP} bed {CHAIN_TO_38} {{MODELNAME}}/tmp/{{MODELNAME}}.bed {MODELNAME}/lifted/{MODELNAME}_lifted.bed")
			if GENOBUILD == "hg19":
				shell(f"{CROSSMAP} bed {CHAIN_TO_19} {{MODELNAME}}/tmp/{{MODELNAME}}.bed {MODELNAME}/lifted/{MODELNAME}_lifted.bed")
		else: # just cp not lifted bed over to 
			shell(f"cp {{MODELNAME}}/tmp/{{MODELNAME}}.bed {MODELNAME}/lifted/{MODELNAME}_lifted.bed; "
			      f"touch {{MODELNAME}}/lifted/{{MODELNAME}}_lifted.bed.unmap")	

rule remove_unlifted_variants: # Remove variants that were not lifted over from the model file
	input: get_remove_unlifted_variants_input
	output: "{MODELNAME}/CLEAN_REF_{MODELNAME}.txt"
	params:
		awk_string = "\'{print $1,$3}\' OFS=\'\t\'"
		#unmap = "{MODELNAME}/lifted/{MODELNAME}_lifted.bed.unmap"
	run:
		if os.stat(str(input)).st_size > 0:
			shell(f"grep -v  ^# {{input}} | awk {{params.awk_string}} > {MODELNAME}/tmp/{MODELNAME}_unlifted_to_REMOVE; "
			      f"grep -vwf {MODELNAME}/tmp/{MODELNAME}_unlifted_to_REMOVE {MODELFILE} > {{output}}")

rule get_ambiguous_variants: # get list of variants that have ambiguous nucleotides
	input: "{MODELNAME}/CLEAN_REF_{MODELNAME}.txt"
	output: "{MODELNAME}/CLEAN_REF_{MODELNAME}_FINAL.txt"
	params: 
		awk_string = "\'FNR>1{if(($3 == \"A\" && $4 == \"T\") || ($3 == \"T\" && $4 == \"A\") || ($3 == \"C\" && $4 == \"G\") || ($3 == \"G\" && $4 == \"C\")) print $1,$4} OFS=\'\t\'"
	run:
		shell(f"grep -v ^# {{input}} | awk {{params.awk_string}} > {MODELNAME}/{MODELNAME}_ambiguous.snps; "
			  f"grep -vwf {MODELNAME}/{MODELNAME}_ambiguous.snps {{input}} > {{output}}")
